{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ea6c1da-d18d-4f73-aaf6-2a99ed561886",
   "metadata": {},
   "source": [
    "# Q1. What is Lasso Regression, and how does it differ from other regression techniques?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e147342-df52-4bb6-bb72-3403d7eb48f9",
   "metadata": {},
   "source": [
    "- Lasso Regression is a regularization technique used over regression methods for more accurate prediction. This model uses shrinkage where data values are shrunk towards a central point as the mean. The lasso procedure encourages simple, sparse models.\n",
    "- Lasso Regression is different from Ridge Regression as it uses absolute coefficient values for normalization. As the loss function only considers absolute coefficients (weights), the optimization algorithm will penalize high coefficients. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb608e8c-69c1-4429-8376-015c3bec4f0f",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f4af36-2f87-409b-a28a-d04f1dd95a1e",
   "metadata": {},
   "source": [
    "# Q2. What is the main advantage of using Lasso Regression in feature selection?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1caedf2c-e957-493f-970f-c29f66868185",
   "metadata": {},
   "source": [
    "- The main advantage of using Lasso Regression in feature selection is that it is scalable to datasets with a large number of features whereas manual implementation would be computationally expensive and tedious.\n",
    "-  Lasso regression will automatically select those features that are useful, discarding the useless or redundant features. In Lasso regression, discarding a feature will make its coefficient equal to 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e450a63-7314-4dd7-889a-900390174f3e",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f69ecd1-d81b-4302-8093-83277fb0b25a",
   "metadata": {},
   "source": [
    "# Q3. How do you interpret the coefficients of a Lasso Regression model?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1988105d-3626-4101-a4fb-5974b8c7934a",
   "metadata": {},
   "source": [
    "- The interpretation of the coefficients of a Lasso Regression model is similar to that of linear regression.\n",
    "- The coefficients represent the change in the dependent variable for a one-unit change in the independent variable while holding all other independent variables constant.\n",
    "- The exponentiated coefficients from the Lasso regression can be interpreted as the log odds for a 1 unit change in the coefficient while holding all other coefficients constant."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a1c21e-49ef-4797-8fd1-d83ceec162cd",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf8e3ca-5768-439e-871c-07ef2ce66bd5",
   "metadata": {},
   "source": [
    "# Q4. What are the tuning parameters that can be adjusted in Lasso Regression, and how do they affect the model's performance?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d33032-8aa6-43b6-be3c-9b52c0551a56",
   "metadata": {},
   "source": [
    "- The tuning parameter in Lasso Regression is the regularization parameter λ. It controls the strength of the penalty term and determines the amount of shrinkage applied to the coefficients.\n",
    "- The value of λ can be adjusted to optimize the model’s performance. \n",
    "- A larger value of λ will result in more shrinkage and more coefficients being set to zero, which can lead to a simpler model with fewer predictors. A smaller value of λ will result in less shrinkage and more coefficients being retained, which can lead to a more complex model with more predictors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d17a3c-ea5b-435c-b444-df431ba02c88",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ad8982-4284-4939-926e-dd1adaf79a16",
   "metadata": {},
   "source": [
    "# Q5. Can Lasso Regression be used for non-linear regression problems? If yes, how?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceaab9f6-a0b5-4989-b09d-b716cfb5755b",
   "metadata": {},
   "source": [
    "- Yes, Lasso Regression can be used for non-linear regression problems.\n",
    "-  One way to do this is by using Gaussian basis functions and applying Lasso regularization. Regularization with a Lasso penalty estimates some coefficients in linear regression models to be exactly zero.\n",
    "-  Another way is to linearize the model and then use Lasso Regression for an approximate solution in the least squares sense."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce0f9df0-f0e8-4e63-a604-274ad35ea2e1",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15559f47-066f-4987-a6f0-b0d1dba60dec",
   "metadata": {},
   "source": [
    "# Q6. What is the difference between Ridge Regression and Lasso Regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b474ac-a621-4db3-9943-042ef1d6e33f",
   "metadata": {},
   "source": [
    "-  The main difference between Ridge and Lasso Regression is the way they shrink the coefficients. \n",
    "- Ridge Regression shrinks the coefficients towards zero by adding a penalty term to the cost function. The penalty term is proportional to the square of the magnitude of the coefficients.\n",
    "- Lasso Regression, on the other hand, tends to make coefficients absolute zero by adding a penalty term proportional to the absolute value of the magnitude of the coefficients."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b12cff6-c66c-44fa-bbfc-2691a80d4bae",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "202a1356-6396-4ffe-845f-9485ac562700",
   "metadata": {},
   "source": [
    "# Q7. Can Lasso Regression handle multicollinearity in the input features? If yes, how?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8579d89-697a-44da-a7e8-6c681a137617",
   "metadata": {},
   "outputs": [],
   "source": [
    "- Lasso Regression can handle multicollinearity to some extent without sacrificing interpretability.\n",
    "- If the collinearity is too high, however, Lasso Regression’s variable selection performance will start to suffer.\n",
    "-  Lasso Regression is a linear regression technique with L1 prior as a regularizer. The idea is to reduce the multicollinearity by regularization by reducing the coefficients of the feature that are multicollinear"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
