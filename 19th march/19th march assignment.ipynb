{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd791d86-2b41-4fbf-9629-9dd3d38b2427",
   "metadata": {},
   "source": [
    "# Q1: What are missing values in a dataset? Why is it essential to handle missing values? Name some algorithms that are not affected by missing values.\n",
    "\n",
    "---> Missing values in a dataset refer to the absence of an observation for a particular variable.\n",
    "\n",
    "---> It is essential to handle missing values because many machine learning algorithms fail if the dataset contains missing values.\n",
    "\n",
    "---> Algorithms that are not affected by missing values are \n",
    "    1) Regresson\n",
    "    2) Naive Bayes\n",
    "    3) K-nearest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a65d285-49bf-4106-828d-86ff4870e6cd",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d236b5-0116-4a60-84f5-0512bc9e03a4",
   "metadata": {},
   "source": [
    "# Q2: List down techniques used to handle missing data.  Give an example of each with python code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df18e19c-e5ca-40ff-acac-11c2377f8b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1)  Dropping missing data: This is the easiest way to handle missing values in Python. You can get rid of the rows or columns where there is missing information.\n",
    "# code:\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('data.csv')\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "#2) Imputing missing data with a specific value: You can replace missing values with a specific value such as mean, median or mode.\n",
    "# code:\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('data.csv')\n",
    "df.fillna(df.mean(), inplace=True)\n",
    "\n",
    "#3) Using machine learning algorithms: You can use machine learning algorithms such as KNN (K-Nearest Neighbors) to impute missing values.\n",
    "#code:\n",
    "import pandas as pd\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "df = pd.read_csv('data.csv')\n",
    "imputer = KNNImputer(n_neighbors=5)\n",
    "df_imputed = imputer.fit_transform(df)\n",
    "\n",
    "#4) Using deep learning algorithms: You can use deep learning algorithms such as Autoencoders to impute missing values. \n",
    "#code:\n",
    "import pandas as pd\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "df = pd.read_csv('data.csv')\n",
    "input_layer = Input(shape=(n_features,))\n",
    "encoded = Dense(32, activation='relu')(input_layer)\n",
    "decoded = Dense(n_features, activation='sigmoid')(encoded)\n",
    "autoencoder = Model(input_layer, decoded)\n",
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "autoencoder.fit(df, df, epochs=100)\n",
    "df_imputed = autoencoder.predict(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00acd9ed-9501-4107-bdbb-1728ccace9fe",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c8ff7b-1172-4703-979e-5693d63d1045",
   "metadata": {},
   "source": [
    "# Q3: Explain the imbalanced data. What will happen if imbalanced data is not handled?\n",
    "\n",
    "---> Imbalanced data refers to a situation, primarily in classification machine learning, where one target class represents a significant        portion of observations.\n",
    "\n",
    "---> If imbalanced data is not handled properly, it can lead to poor performance of the model. \n",
    "\n",
    "---> The model may be biased towards the majority class and may not be able to predict the minority class accurately.\n",
    "\n",
    "---> This can lead to false negatives or false positives.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6e8890-bdea-4103-90cf-25ae9fed17b2",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1365b15-0ae8-4f06-89b4-cb02776ff391",
   "metadata": {},
   "source": [
    "# Q4: What are Up-sampling and Down-sampling? Explain with an example when up-sampling and downsampling are required.\n",
    "\n",
    "---> Up-sampling and Down-sampling are techniques used to handle unbalanced data.\n",
    "\n",
    "* Up-sampling:\n",
    "\n",
    "---> Up-sampling involves adding more samples to the minority class so that it becomes balanced with the majority class. \n",
    "\n",
    "--->  This can be useful when you have a small dataset and removing some samples will affect the overall performance of the model.\n",
    "\n",
    "---> Example: Suppose you have a dataset with 1000 samples, out of which 100 belong to class A and 900 belong to class B. In this case, you can add more samples to class A so that it becomes balanced with class B.\n",
    "\n",
    "\n",
    "* Down-sampling:\n",
    "\n",
    "---> Down-sampling involves removing some samples from the majority class so that it becomes balanced with the minority class.\n",
    "\n",
    "---> This can be useful when you have a large dataset and removing some samples will not affect the overall performance of the model.\n",
    "\n",
    "---> Example: Suppose you have a dataset with 1000 samples, out of which 900 belong to class A and 100 belong to class B. In this case, you can remove some samples from class A so that it becomes balanced with class B."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a8fe9c1-a861-461c-8489-5c2ec7edeb08",
   "metadata": {},
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27975d62-c4dd-4cb4-9494-6bb57902aac4",
   "metadata": {},
   "source": [
    "# Q5: What is data Augmentation? Explain SMOTE.\n",
    "\n",
    "* Data Augmentation\n",
    "\n",
    "---> Data augmentation is a technique used to increase the size of a dataset by creating new data from the existing data.\n",
    "\n",
    "---> This can be useful when you have a small dataset and you want to improve the performance of your model.\n",
    "\n",
    "---> Data augmentation can be done in several ways such as flipping, rotating, cropping, zooming, etc.\n",
    "\n",
    "* SMOTE\n",
    "\n",
    "---> SMOTE stands for Synthetic Minority Over-sampling Technique.\n",
    "\n",
    "---> It is a data augmentation algorithm that creates synthetic data points from raw data.\n",
    "\n",
    "--->  SMOTE is widely used in preprocessing imbalanced datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02678473-0b76-46ab-b3cb-3942355080e3",
   "metadata": {},
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb1f9bd2-36d8-4d2b-b818-3d041a59d5fa",
   "metadata": {},
   "source": [
    "# Q6: What are outliers in a dataset? Why is it essential to handle outliers?\n",
    "\n",
    "---> An outlier in a data set is a value that is much larger or smaller than the others, or that lies an abnormal distance from the rest of the observations.\n",
    "\n",
    "---> It is essential to handle outliers because they can have a significant impact on statistical analysis. Outliers can skew results and make it difficult to identify patterns in data.\n",
    "\n",
    "--->  They can also lead to incorrect conclusions about relationships between variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503c93bf-afef-41f6-b358-c73e93379ae1",
   "metadata": {},
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ccaa62-ce92-482f-8a70-0ab27d21f991",
   "metadata": {},
   "source": [
    "# Q7: You are working on a project that requires analyzing customer data. However, you notice that some of the data is missing. What are some techniques you can use to handle the missing data in your analysis?\n",
    "\n",
    "---> There are several techniques to handle the missing data.\n",
    "\n",
    "---> One way is to delete the observations with missing values. \n",
    "\n",
    "---> Another technique is to impute the missing values. This involves filling in the missing values with estimated values based on the available data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc9f63c0-f94f-4aa6-9cc6-8fec5530d0f1",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b4c4f16-7a47-4a6b-86ed-3b123ef1f8bd",
   "metadata": {},
   "source": [
    "# Q8: You are working with a large dataset and find that a small percentage of the data is missing. What are some strategies you can use to determine if the missing data is missing at random or if there is a pattern to the missing data?\n",
    "\n",
    "--->  One way is to use your substantive scientific knowledge of the data and your field. The more sensitive the issue, the less likely people are to tell you.\n",
    "\n",
    "---> Another way is to use statistical tests. There are statistical tests to determine if the data is missing at random (MAR), but given that you need some hypothesis about missing values and where you expect them, endless testing seems a bit cumbersome.\n",
    "\n",
    "---> You can also use visualization techniques to explore the data visually and stay attentive to potential method-related biases in case you have no strong ideas right-away"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef2bf9a-a81a-4d07-8ba8-7d51d98c0eb5",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e362b52-1665-40aa-ba7a-cb9c88103c2a",
   "metadata": {},
   "source": [
    "# Q9: Suppose you are working on a medical diagnosis project and find that the majority of patients in thedataset do not have the condition  of interest, while a small percentage do. What are some strategies you can use to evaluate the performance of your machine learning model on this imbalanced dataset?\n",
    "\n",
    "---> One way is to use appropriate evaluation metrics. When dealing with an imbalanced dataset, it is crucial to use appropriate metrics to evaluate the model’s performance. Accuracy is not an appropriate metric as it can be misleading in an imbalanced dataset.\n",
    "\n",
    "---> Another way is to use resampling techniques such as oversampling or undersampling.\n",
    "\n",
    "---> Oversampling involves increasing the number of instances in the minority class by generating synthetic samples.\n",
    "\n",
    "---> Undersampling involves reducing the number of instances in the majority class by randomly removing samples.\n",
    "\n",
    "---> Ensemble methods can also be used to balance the dataset and improve model performance. Ensemble methods involve combining multiple models to improve overall performance.\n",
    "\n",
    "---> Cost-sensitive learning can also be used to balance the dataset and improve model performance. Cost-sensitive learning involves assigning different costs to different types of errors.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01cb34fe-1a88-4ed2-8db7-171860ca229b",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c457c59e-18e3-45d2-8191-43661ab12ed9",
   "metadata": {},
   "source": [
    "# Q10: When attempting to estimate customer satisfaction for a project, you discover that the dataset is unbalanced, with the bulk of customers reporting being satisfied. What methods can you employ to balance the dataset and down-sample the majority class?\n",
    "\n",
    "---> One way is to use resampling techniques such as oversampling or undersampling.\n",
    "\n",
    "---> Oversampling involves increasing the number of instances in the minority class by generating synthetic samples.\n",
    "\n",
    "---> Undersampling involves reducing the number of instances in the majority class by randomly removing samples.\n",
    "\n",
    "---> Another way is to use cost-sensitive learning techniques. Cost-sensitive learning involves assigning different costs to different types of errors.\n",
    "\n",
    "---> Ensemble methods can also be used to balance the dataset and improve model performance. Ensemble methods involve combining multiple models to improve overall performance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab3ec0f6-6026-41f4-9518-558a5cfc0006",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d71209-cff0-4656-92c6-175624ccf33b",
   "metadata": {},
   "source": [
    "# Q11: You discover that the dataset is unbalanced with a low percentage of occurrences while working on a project that requires you to estimate the occurrence of a rare event. What methods can you employ to balance the dataset and up-sample the minority class?\n",
    "\n",
    "---> There are several methods that can be employed to balance an unbalanced dataset and up-sample the minority class.\n",
    "\n",
    "1) Collect more data\n",
    "2) Try changing your performance metric\n",
    "3) Try resambling your dataset\n",
    "4) Try generating synthetic samples\n",
    "5) Try different algorithms\n",
    "6) Try penalized models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ccb58d3-4507-4c32-a7a3-f27baec1dff5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
